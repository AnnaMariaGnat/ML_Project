{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Needed libraries '''\n",
    "\n",
    "import numpy as np # For matrix operations and numerical processing\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import os, sys # For filepaths\n",
    "import torch # For building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Add the datasets and libraries to the system path '''\n",
    "\n",
    "# Find the path to our implementations\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "home_directory = os.path.dirname(parent_directory)\n",
    "libraries_path = os.path.join(home_directory, 'Libraries')\n",
    "\n",
    "# Find the path to the datasets\n",
    "datasets_path = os.path.join(home_directory, 'Datasets')\n",
    "\n",
    "# Add them both to the system path\n",
    "sys.path.append(datasets_path)\n",
    "sys.path.append(libraries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n",
      "(5000, 784)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "''' Loading in the training and test sets '''\n",
    "\n",
    "training_set = np.load(os.path.join(datasets_path, 'fashion_train.npy'))  # Load train set\n",
    "train_X = training_set[:, :-1] # Define X as all columns except the last one\n",
    "train_y = training_set[:, -1] # Define y as the last column\n",
    "\n",
    "test_set = np.load(os.path.join(datasets_path, 'fashion_test.npy'))  # Load test set\n",
    "test_X = test_set[:, :-1] # Define X as all columns except the last one\n",
    "test_y = test_set[:, -1] # Define y as the last column\n",
    "\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Convert the data to tensors '''\n",
    "tensor_train_X = torch.from_numpy(train_X).float() # Convert to float tensor\n",
    "tensor_train_y = torch.from_numpy(train_y).long() # Convert to long tensor\n",
    "tensor_test_X = torch.from_numpy(test_X).float() # Convert to float tensor\n",
    "tensor_test_y = torch.from_numpy(test_y).long() # Convert to long tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create tensors for training and test sets '''\n",
    "train = torch.utils.data.TensorDataset(tensor_train_X, tensor_train_y) # Create a training set\n",
    "test = torch.utils.data.TensorDataset(tensor_test_X, tensor_test_y) # Create a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define NN architecture '''\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define parameters and initialize the neural network '''\n",
    "input_size = train_X.shape[1] # Number of features per sample\n",
    "hidden_size = 1000 # Number of nodes in the hidden layer\n",
    "number_of_classes = len(np.unique(train_y)) # Number of classes\n",
    "\n",
    "\n",
    "neural_network = NeuralNetwork(input_size, hidden_size, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Loss function and optimizer '''\n",
    "loss_function = torch.nn.CrossEntropyLoss() # Cross entropy loss function\n",
    "# optimizer = torch.optim.Adam(neural_network.parameters(), lr=0.001) # Adam optimizer\n",
    "# optimizer = torch.optim.SGD(neural_network.parameters(), lr=0.001) # SGD optimizer\n",
    "# optimizer = torch.optim.SGD(neural_network.parameters(), lr=0.001, momentum=0.9) # SGD optimizer with momentum\n",
    "# optimizer = torch.optim.SGD(neural_network.parameters(), lr=0.001, momentum=0.9, nesterov=True) # SGD optimizer with momentum and Nesterov momentum\n",
    "# optimizer = torch.optim.Adagrad(neural_network.parameters(), lr=0.001) # Adagrad optimizer\n",
    "# optimizer = torch.optim.RMSprop(neural_network.parameters(), lr=0.001) # RMSprop optimizer\n",
    "optimizer = torch.optim.Adamax(neural_network.parameters(), lr=0.001) # Adamax optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Step: 100/100, Loss: 0.2523\n",
      "Epoch: 2/10, Step: 100/100, Loss: 0.1968\n",
      "Epoch: 3/10, Step: 100/100, Loss: 0.2645\n",
      "Epoch: 4/10, Step: 100/100, Loss: 0.1993\n",
      "Epoch: 5/10, Step: 100/100, Loss: 0.2256\n",
      "Epoch: 6/10, Step: 100/100, Loss: 0.2551\n",
      "Epoch: 7/10, Step: 100/100, Loss: 0.1614\n",
      "Epoch: 8/10, Step: 100/100, Loss: 0.3035\n",
      "Epoch: 9/10, Step: 100/100, Loss: 0.1769\n",
      "Epoch: 10/10, Step: 100/100, Loss: 0.1782\n"
     ]
    }
   ],
   "source": [
    "''' Training the neural network '''\n",
    "batch_size = 100 # Number of samples per batch\n",
    "num_epochs = 10 # Number of epochs\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True) # Create a train loader\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, input_size) # Reshape the images to vectors\n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "        outputs = neural_network(images) # Forward pass\n",
    "        loss = loss_function(outputs, labels) # Calculate the loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Update the weights\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step: {i+1}/{len(train_loader)}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 5000 test images: 84.36%\n"
     ]
    }
   ],
   "source": [
    "''' Testing the neural network '''\n",
    "neural_network.eval() # Set the model to evaluation mode\n",
    "correct = 0 # Initialize the number of correct predictions\n",
    "total = 0 # Initialize the total number of predictions\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False) # Create a test loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculation\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, input_size) # Reshape the images to vectors\n",
    "        outputs = neural_network(images) # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1) # Get the predicted class\n",
    "        total += labels.size(0) # Add the number of labels\n",
    "        correct += (predicted == labels).sum().item() # Add the number of correct predictions\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_loader)*batch_size} test images: {100*correct/total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
