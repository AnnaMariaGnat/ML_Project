{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, sys # For filepaths\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pickle\n",
    "import sklearn.preprocessing as pre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Add the datasets and libraries to the system path '''\n",
    "\n",
    "# Find the path to our implementations\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "home_directory = os.path.dirname(parent_directory)\n",
    "libraries_path = os.path.join(home_directory, 'Libraries')\n",
    "\n",
    "# Find the path to the datasets\n",
    "datasets_path = os.path.join(home_directory, 'Datasets')\n",
    "\n",
    "# Add them both to the system path\n",
    "sys.path.append(datasets_path)\n",
    "sys.path.append(libraries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "''' Load the dataset '''\n",
    "\n",
    "dataset = np.load(os.path.join(datasets_path, 'fashion_train.npy'))\n",
    "print(\"Dataset shape: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :-1]  # Define the images as all columns except the last one\n",
    "y = dataset[:, -1] # Define the labels as the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "X shape:  (10000, 784)\n",
      "<class 'numpy.ndarray'>\n",
      "y shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(\"X shape: \", X.shape)\n",
    "print(type(y))\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the images\n",
    "scaler = pre.StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifiers \n",
    "from sklearn import svm \n",
    "from CNN import CNN\n",
    "from Bayes import Bayes_classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y_val): \n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for yt, yp in zip(y_val, predictions):\n",
    "        if yt == yp:\n",
    "            correct_predictions += 1\n",
    "    return correct_predictions/predictions.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8633"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(svm.SVC(C=10), X, y, cv=5, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638848172810455"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(svm.SVC(C=10), X, y, cv=5, scoring = 'precision_macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634444008462324"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(svm.SVC(C=10), X, y, cv=5, scoring = 'f1_macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640947070385945"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(svm.SVC(C=10), X, y, cv=5, scoring = 'recall_macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(CNN(), X, y, cv=5, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(CNN(), X, y, cv=5, scoring = 'precision_macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(CNN(), X, y, cv=5, scoring = 'f1_macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(CNN(), X, y, cv=5, scoring = 'recall_macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ITU\\Machine_learning\\ML_Project\\Libraries\\Bayes.py:61: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  denom = sum(np.multiply(self.class_priors(),self.pdf(test_x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ITU\\Machine_learning\\ML_Project\\Libraries\\Bayes.py:61: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  denom = sum(np.multiply(self.class_priors(),self.pdf(test_x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6952999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(Bayes_classifier(0.5), X, y, cv=5, scoring = 'accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 784)\n",
      "Classifier 1 - Bayes\n",
      "(2000, 2)\n",
      "(2000, 784)\n",
      "Classifier 1 - Bayes\n",
      "(2000, 2)\n",
      "(2000, 784)\n",
      "Classifier 1 - Bayes\n",
      "(2000, 2)\n",
      "(2000, 784)\n",
      "Classifier 1 - Bayes\n",
      "(2000, 2)\n",
      "(2000, 784)\n",
      "Classifier 1 - Bayes\n",
      "(2000, 2)\n",
      "############ Classifier 1 - Bayes:\n",
      "Average F1 score = 0.228\n",
      "Average Accuracy = 0.228\n",
      "Average Precision = 0.228\n",
      "Average Recall = 0.228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        ...,\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531]]),\n",
       " array([0, 1, 0, ..., 4, 3, 1], dtype=uint8),\n",
       " array([[-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        ...,\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531],\n",
       "        [-0.0148165 , -0.03760239, -0.06245122, ..., -0.14119802,\n",
       "         -0.06592056, -0.02908531]]),\n",
       " array([1, 2, 0, ..., 3, 0, 1], dtype=uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define classifiers\n",
    "classifiers = [Bayes_classifier(3)]\n",
    "classifier_names = [\"Bayes\"]\n",
    "num_classifiers = len(classifiers)\n",
    "num_folds = 5\n",
    "\n",
    "group_kfold = KFold(n_splits=num_folds)\n",
    "\n",
    "# Define functions to avoid code repetition\n",
    "def get_metrics(classifiers, x, y):\n",
    "    acc_val = np.empty([num_folds, num_classifiers])\n",
    "    f1_val = np.empty([num_folds, num_classifiers])\n",
    "    precision = np.empty([num_folds, num_classifiers])\n",
    "    recall = np.empty([num_folds, num_classifiers])\n",
    "    # roc_auc = np.empty([num_folds, num_classifiers])\n",
    "    for i, (train_index, val_index) in enumerate(group_kfold.split(x, y)):\n",
    "        x_train, x_val = x[train_index, :], x[val_index, :]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        print(x_val.shape)\n",
    "        for j, clf in enumerate(classifiers):\n",
    "            print(f\"Classifier {j+1} - {classifier_names[j]}\")\n",
    "            clf.fit(x_train, y_train)\n",
    "            predictions = clf.predict(x_val)\n",
    "            acc_val[i, j] = accuracy_score(y_val, predictions)\n",
    "            f1_val[i, j] = f1_score(y_val, predictions, average='micro')\n",
    "            precision[i, j] = precision_score(y_val, predictions, zero_division=0, average='micro')\n",
    "            recall[i, j] = recall_score(y_val, predictions, average='micro')\n",
    "    print_metrics(acc_val, f1_val, precision, recall)\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "def print_metrics(acc_val, f1_val, precision, recall):\n",
    "    average_acc = np.mean(acc_val, axis=0)\n",
    "    average_f1 = np.mean(f1_val, axis=0)\n",
    "    average_precision = np.mean(precision, axis=0)\n",
    "    average_recall = np.mean(recall, axis=0)\n",
    "    for i, classifier_name in enumerate(classifier_names):\n",
    "        print(f\"############ Classifier {i+1} - {classifier_name}:\")\n",
    "        print(f'Average F1 score = {average_f1[i]:.3f}')\n",
    "        print(f'Average Accuracy = {average_acc[i]:.3f}')\n",
    "        print(f'Average Precision = {average_precision[i]:.3f}')\n",
    "        print(f'Average Recall = {average_recall[i]:.3f}')\n",
    "\n",
    "get_metrics(classifiers, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal feature selection\n",
    "print(\"Running without feature selection\")\n",
    "x_train, y_train, x_val, y_val = get_metrics(classifiers, x, y, patient_id)\n",
    "\n",
    "# Feature selection with variance threshold\n",
    "print(\"Running with variance threshold feature selection\")\n",
    "threshold_value = 0.1\n",
    "selector = VarianceThreshold(threshold=threshold_value)\n",
    "x_selected = selector.fit_transform(x)\n",
    "get_metrics(classifiers, x_selected, y, patient_id, \"With variance threshold\")\n",
    "\n",
    "# Feature selection with PCA\n",
    "print(\"Running with PCA feature selection\")\n",
    "pca_transformer = PCA(n_components=5)\n",
    "x_pca = pca_transformer.fit_transform(x)\n",
    "get_metrics(classifiers, x_pca, y, patient_id, \"With PCA\")\n",
    "\n",
    "# Define the path where to save the file\n",
    "pickle_path = 'Project-2_github_repo/Fixed/PROJECT/fyp2023/model_group02'\n",
    "\n",
    "# Chosen classifier\n",
    "classifier = KNN(n_neighbors=5)\n",
    "classifier = classifier.fit(x, y)\n",
    "filename = 'group02_classifier.sav'\n",
    "\n",
    "# Check if the path exists, if not, create it\n",
    "if not os.path.exists(pickle_path):\n",
    "    os.makedirs(pickle_path)\n",
    "\n",
    "pickle.dump(classifier, open(os.path.join(pickle_path, filename), 'wb'))\n",
    "\n",
    "\n",
    "# Plot ROC curve for best classifier\n",
    "clf = classifier\n",
    "clf.fit(x_train, y_train)\n",
    "y_score = clf.predict_proba(x_val)\n",
    "fpr, tpr, _ = roc_curve(y_val, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
