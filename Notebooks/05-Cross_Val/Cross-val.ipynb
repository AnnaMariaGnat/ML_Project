{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os, sys # For filepaths\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Add the datasets and libraries to the system path '''\n",
    "\n",
    "# Find the path to our implementations\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "home_directory = os.path.dirname(parent_directory)\n",
    "libraries_path = os.path.join(home_directory, 'Libraries')\n",
    "\n",
    "# Find the path to the datasets\n",
    "datasets_path = os.path.join(home_directory, 'Datasets')\n",
    "\n",
    "# Add them both to the system path\n",
    "sys.path.append(datasets_path)\n",
    "sys.path.append(libraries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "''' Load the dataset '''\n",
    "\n",
    "dataset = np.load(os.path.join(datasets_path, 'fashion_train.npy'))\n",
    "print(\"Dataset shape: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :-1]  # Define the images as all columns except the last one\n",
    "y = dataset[:, -1] # Define the labels as the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "X shape:  (10000, 784)\n",
      "<class 'numpy.ndarray'>\n",
      "y shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(\"X shape: \", X.shape)\n",
    "print(type(y))\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Ania's FYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifiers \n",
    "from sklearn import svm \n",
    "from CNN import CNN\n",
    "#from Bayes import Bayes_classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1 - CNN\n",
      "Classifier 2 - KNN\n",
      "Classifier 1 - CNN\n"
     ]
    }
   ],
   "source": [
    "# Define classifiers\n",
    "classifiers = [CNN(), KNN(5)]\n",
    "classifier_names = [\"CNN\", \"KNN\"]\n",
    "num_classifiers = len(classifiers)\n",
    "num_folds = 5\n",
    "\n",
    "group_kfold = KFold(n_splits=num_folds)\n",
    "\n",
    "# Define functions to avoid code repetition\n",
    "def get_metrics(classifiers, x, y):\n",
    "    acc_val = np.empty([num_folds, num_classifiers])\n",
    "    f1_val = np.empty([num_folds, num_classifiers])\n",
    "    precision = np.empty([num_folds, num_classifiers])\n",
    "    recall = np.empty([num_folds, num_classifiers])\n",
    "    # roc_auc = np.empty([num_folds, num_classifiers])\n",
    "    for i, (train_index, val_index) in enumerate(group_kfold.split(x, y)):\n",
    "        x_train, x_val = x[train_index, :], x[val_index, :]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        for j, clf in enumerate(classifiers):\n",
    "            print(f\"Classifier {j+1} - {classifier_names[j]}\")\n",
    "            clf.fit(x_train, y_train)\n",
    "            predictions = clf.predict(x_val)\n",
    "            if classifier_names[j] == \"CNN\":\n",
    "                predictions = np.array(predictions)\n",
    "                predictions = predictions.astype(int)\n",
    "                predictions = predictions.reshape(predictions.shape[0],)\n",
    "            acc_val[i, j] = accuracy_score(y_val, predictions)\n",
    "            f1_val[i, j] = f1_score(y_val, predictions, average='micro')\n",
    "            precision[i, j] = precision_score(y_val, predictions, zero_division=0, average='micro')\n",
    "            recall[i, j] = recall_score(y_val, predictions, average='micro')\n",
    "    print_metrics(acc_val, f1_val, precision, recall)\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "def print_metrics(acc_val, f1_val, precision, recall, roc_auc):\n",
    "    average_acc = np.mean(acc_val, axis=0)\n",
    "    average_f1 = np.mean(f1_val, axis=0)\n",
    "    average_precision = np.mean(precision, axis=0)\n",
    "    average_recall = np.mean(recall, axis=0)\n",
    "    for i, classifier_name in enumerate(classifier_names):\n",
    "        print(f\"############ Classifier {i+1} - {classifier_name}:\")\n",
    "        print(f'Average F1 score = {average_f1[i]:.3f}')\n",
    "        print(f'Average Accuracy = {average_acc[i]:.3f}')\n",
    "        print(f'Average Precision = {average_precision[i]:.3f}')\n",
    "        print(f'Average Recall = {average_recall[i]:.3f}')\n",
    "\n",
    "x_train, y_train, x_val, y_val = get_metrics(classifiers, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal feature selection\n",
    "print(\"Running without feature selection\")\n",
    "x_train, y_train, x_val, y_val = get_metrics(classifiers, x, y, patient_id)\n",
    "\n",
    "# Feature selection with variance threshold\n",
    "print(\"Running with variance threshold feature selection\")\n",
    "threshold_value = 0.1\n",
    "selector = VarianceThreshold(threshold=threshold_value)\n",
    "x_selected = selector.fit_transform(x)\n",
    "get_metrics(classifiers, x_selected, y, patient_id, \"With variance threshold\")\n",
    "\n",
    "# Feature selection with PCA\n",
    "print(\"Running with PCA feature selection\")\n",
    "pca_transformer = PCA(n_components=5)\n",
    "x_pca = pca_transformer.fit_transform(x)\n",
    "get_metrics(classifiers, x_pca, y, patient_id, \"With PCA\")\n",
    "\n",
    "# Define the path where to save the file\n",
    "pickle_path = 'Project-2_github_repo/Fixed/PROJECT/fyp2023/model_group02'\n",
    "\n",
    "# Chosen classifier\n",
    "classifier = KNN(n_neighbors=5)\n",
    "classifier = classifier.fit(x, y)\n",
    "filename = 'group02_classifier.sav'\n",
    "\n",
    "# Check if the path exists, if not, create it\n",
    "if not os.path.exists(pickle_path):\n",
    "    os.makedirs(pickle_path)\n",
    "\n",
    "pickle.dump(classifier, open(os.path.join(pickle_path, filename), 'wb'))\n",
    "\n",
    "\n",
    "# Plot ROC curve for best classifier\n",
    "clf = classifier\n",
    "clf.fit(x_train, y_train)\n",
    "y_score = clf.predict_proba(x_val)\n",
    "fpr, tpr, _ = roc_curve(y_val, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
